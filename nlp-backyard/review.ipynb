{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.生成句子实例一：简单语料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 语料1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_grammar = \"\"\"\n",
    "sentence => noun_phrase verb_phrase\n",
    "noun_phrase => Article Adj* noun\n",
    "Adj* => null | Adj Adj*\n",
    "verb_phrase => verb noun_phrase\n",
    "Article =>  一个 | 这个\n",
    "noun =>   女人 |  篮球 | 桌子 | 小猫\n",
    "verb => 看着   |  坐在 |  听着 | 看见\n",
    "Adj =>  蓝色的 | 好看的 | 小小的\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 一些Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def adj(): return random.choice('蓝色的 | 好看的 | 小小的'.split('|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'蓝色的 '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['sentence ', ' noun_phrase verb_phrase'], ['noun_phrase ', ' Article Adj* noun'], ['Adj* ', ' null | Adj Adj*'], ['verb_phrase ', ' verb noun_phrase'], ['Article ', '  一个 | 这个'], ['noun ', '   女人 |  篮球 | 桌子 | 小猫'], ['verb ', ' 看着   |  坐在 |  听着 | 看见'], ['Adj ', '  蓝色的 | 好看的 | 小小的']]\n"
     ]
    }
   ],
   "source": [
    "print([element.split('=>') for element in [entry for entry in simple_grammar.split('\\n')][1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, False, False, False, False, False, False, False, False, True]\n"
     ]
    }
   ],
   "source": [
    "print([not element.strip() for element in [entry for entry in simple_grammar.split('\\n')]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentence => noun_phrase verb_phrase', 'noun_phrase => Article Adj* noun', 'Adj* => null | Adj Adj*', 'verb_phrase => verb noun_phrase', 'Article =>  一个 | 这个', 'noun =>   女人 |  篮球 | 桌子 | 小猫', 'verb => 看着   |  坐在 |  听着 | 看见', 'Adj =>  蓝色的 | 好看的 | 小小的']\n"
     ]
    }
   ],
   "source": [
    "print([entry for entry in simple_grammar.split('\\n') if entry!=''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 主体代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grammar(material,com_mark='\\n',spec_mark='=>'):\n",
    "    gram = {}\n",
    "    for entry in material.split(com_mark):            #按\\n划分各行\n",
    "        if not entry.strip(): continue                      #滤掉非空格或\\n\n",
    "        rule,value = entry.split(spec_mark)\n",
    "        rule = rule.strip()\n",
    "        value = value.strip()\n",
    "        gram[rule] = [v.split() for v in value.split('|')]  #得到语法结构\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': [['noun_phrase', 'verb_phrase']], 'noun_phrase': [['Article', 'Adj*', 'noun']], 'Adj*': [['null'], ['Adj', 'Adj*']], 'verb_phrase': [['verb', 'noun_phrase']], 'Article': [['一个'], ['这个']], 'noun': [['女人'], ['篮球'], ['桌子'], ['小猫']], 'verb': [['看着'], ['坐在'], ['听着'], ['看见']], 'Adj': [['蓝色的'], ['好看的'], ['小小的']]}\n"
     ]
    }
   ],
   "source": [
    "gram_struct = grammar(simple_grammar)\n",
    "print(gram_struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'一个' in gram_struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(gram = {},target = 'sentence'): \n",
    "    result = ''\n",
    "    if target not in gram:\n",
    "        #print(target,'not in GRAM.......')\n",
    "        return target\n",
    "    #print('Generating',target,'.......')\n",
    "    #print('Random Choose:',gram[target])\n",
    "    recv = [generator(gram,t) for t in random.choice(gram[target])]\n",
    "    result = ''.join([r for r in recv if r!='null'])\n",
    "    #print('recv:',recv)\n",
    "    #print('result:',result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'坐在这个女人'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(gram_struct ,target = 'verb_phrase')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 输出生成的句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这个篮球看见这个小小的小小的好看的女人\n"
     ]
    }
   ],
   "source": [
    "print(generator(grammar(simple_grammar),'sentence'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.生成句子实例二：西部世界语料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在西部世界里，一个”人类“的语言可以定义为：\n",
    "\n",
    "human = \"\"\"\n",
    "human = 自己 寻找 活动\n",
    "自己 = 我 | 俺 | 我们 \n",
    "寻找 = 找找 | 想找点 \n",
    "活动 = 乐子 | 玩的\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#一个“接待员”的语言可以定义为\n",
    "\n",
    "host = \"\"\"\n",
    "host = 寒暄 报数 询问 业务相关 结尾 \n",
    "报数 = 我是 数字 号 ,\n",
    "数字 = 单个数字 | 数字 单个数字 \n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 \n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称 ,\n",
    "人称 = 先生 | 女士 | 小朋友\n",
    "打招呼 = 你好 | 您好 \n",
    "询问 = 请问你要 | 您需要\n",
    "业务相关 = 玩玩 具体业务\n",
    "玩玩 = null\n",
    "具体业务 = 喝酒 | 打牌 | 打猎 | 赌博\n",
    "结尾 = 吗？\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'host': [['寒暄', '报数', '询问', '业务相关', '结尾']], '报数': [['我是', '数字', '号', ',']], '数字': [['单个数字'], ['数字', '单个数字']], '单个数字': [['1'], ['2'], ['3'], ['4'], ['5'], ['6'], ['7'], ['8'], ['9']], '寒暄': [['称谓', '打招呼'], ['打招呼']], '称谓': [['人称', ',']], '人称': [['先生'], ['女士'], ['小朋友']], '打招呼': [['你好'], ['您好']], '询问': [['请问你要'], ['您需要']], '业务相关': [['玩玩', '具体业务']], '玩玩': [['null']], '具体业务': [['喝酒'], ['打牌'], ['打猎'], ['赌博']], '结尾': [['吗？']]}\n"
     ]
    }
   ],
   "source": [
    "host_gram = grammar(host,spec_mark='=')\n",
    "print(host_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好我是2号,您需要打牌吗？'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(host_gram,target='host')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 生成host句子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "先生,你好我是8号,请问你要打牌吗？\n",
      "你好我是7号,您需要赌博吗？\n",
      "你好我是9号,请问你要打牌吗？\n",
      "你好我是9号,您需要打猎吗？\n",
      "您好我是7号,您需要打猎吗？\n",
      "先生,您好我是42号,请问你要喝酒吗？\n",
      "小朋友,你好我是59号,您需要打牌吗？\n",
      "您好我是28号,您需要打猎吗？\n",
      "你好我是1号,您需要打牌吗？\n",
      "您好我是71号,请问你要喝酒吗？\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(generator(grammar(host,spec_mark='='),target='host'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 生成human句子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我们找找玩的\n",
      "我们找找玩的\n",
      "我想找点乐子\n",
      "我们找找乐子\n",
      "我想找点乐子\n",
      "我们找找玩的\n",
      "俺想找点乐子\n",
      "俺想找点玩的\n",
      "我们找找玩的\n",
      "我找找乐子\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(generator(grammar(human,spec_mark='='),target='human'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.基于数据的Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 何为language model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### language model : 计算一句话出现的概率P(String)判断其是否合理，P(String)∈(0,1)，越接近1则越合理，反之越不合理。\n",
    "\n",
    "$$ 数学定义：language\\_model(String) = Probability(String) \\in (0, 1) $$\n",
    "\n",
    "$$ 理论模型：N-gram: Pr(w_1 w_2 w_3 ... w_n) = Pr(w_1 | w_2 w_3 ... w_ n) * Pr(w2 | w_3 w_4 ... w_n) * ... * Pr(w_(n-1) | w_n) * Pr(w_n)$$\n",
    "\n",
    "$$ 常见模型：2-gram: Pr(w_1 w_2 w_3 ... w_n) \\sim Pr(w_1 | w_2 ) * P(w2 | w_3 ) * ... * Pr(w_(n-1) | w_n) * Pr(w_n)$$\n",
    "$$ 常见模型：2-gram: Pr(w_1 w_2 w_3 ... w_n) \\sim Pr(w_1) * Pr(w_2 | w_1 ) * P(w3 | w_2 ) * ... * Pr(w_(n-1) | w_n) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 训练新闻语料，判断生成句子的合理性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 语料切分成小文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def split(rawfile,todir,segment):\n",
    "    if not os.path.exists(todir):                            #目录不存在，新建之\n",
    "        os.mkdir(todir)          \n",
    "    else:\n",
    "        for fname in os.listdir(todir):                      #目录已存在，移除并新建      \n",
    "            os.remove(os.path.join(todir,fname))\n",
    "    partnum = 0\n",
    "    inputfile = open(rawfile,'rb')                            \n",
    "    chunksize = int(segment*1024*1000)                        #分割文件大小 = segment*1Mb\n",
    "    while True:\n",
    "        chunk = inputfile.read(chunksize)                     #读取指定长度\n",
    "        if not chunk:                                         #切分完否?\n",
    "            break\n",
    "        partnum += 1\n",
    "        filename = os.path.join(todir,(rawfile+'%04d'%partnum))\n",
    "        fileobj = open(filename,'wb')                          \n",
    "        fileobj.write(chunk)                                   #写入指定长度\n",
    "        fileobj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "split('article_9k.txt','.\\seg',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergecnt(dict1={},dict2={}):\n",
    "    if not dict2: return dict1 \n",
    "    return dict([(k,v+dict1[k]) if k in dict1 else (k,v) for k,v in dict2.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 逐一对小文件进行jieba分词并拼装成Token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "def cut(str):\n",
    "    return jieba.lcut(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInfo(source_dir):                                       #读取切分的文件，并整合\n",
    "    token = []\n",
    "    #word_cnt = {}\n",
    "    for root, sub_dirs, files in os.walk(source_dir):\n",
    "        for special_file in files:\n",
    "            spcial_file_dir = os.path.join(root, special_file)\n",
    "            with open(spcial_file_dir,'rb') as source_file:\n",
    "                for line in source_file:\n",
    "                    token += cut(line)                        #按子文件逐一整合\n",
    "                    #word_cnt = dict(cnt(token))\n",
    "                print('>=',special_file,'done')\n",
    "    print(spcial_file_dir)\n",
    "    print('token length:',len(token))\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ENOCH\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.634 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">= article_9k.txt0001 done\n",
      ">= article_9k.txt0002 done\n",
      ">= article_9k.txt0003 done\n",
      ">= article_9k.txt0004 done\n",
      ">= article_9k.txt0005 done\n",
      ">= article_9k.txt0006 done\n",
      ">= article_9k.txt0007 done\n",
      ">= article_9k.txt0008 done\n",
      ">= article_9k.txt0009 done\n",
      ">= article_9k.txt0010 done\n",
      ".\\seg\\article_9k.txt0010\n",
      "token length: 17627341\n"
     ]
    }
   ],
   "source": [
    "token = getInfo('.\\seg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['此外',\n",
       " '自',\n",
       " '本周',\n",
       " '6',\n",
       " '月',\n",
       " '12',\n",
       " '日起',\n",
       " '除',\n",
       " '小米',\n",
       " '手机',\n",
       " '6',\n",
       " '等',\n",
       " '15',\n",
       " '款',\n",
       " '机型',\n",
       " '外',\n",
       " '其余',\n",
       " '机型',\n",
       " '已',\n",
       " '暂停']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 统计词频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter as cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'此外': 1,\n",
       "         '自': 1,\n",
       "         '本周': 1,\n",
       "         '6': 2,\n",
       "         '月': 1,\n",
       "         '12': 1,\n",
       "         '日起': 1,\n",
       "         '除': 1,\n",
       "         '小米': 1,\n",
       "         '手机': 1,\n",
       "         '等': 1,\n",
       "         '15': 1,\n",
       "         '款': 1,\n",
       "         '机型': 2,\n",
       "         '外': 1,\n",
       "         '其余': 1,\n",
       "         '已': 1,\n",
       "         '暂停': 1,\n",
       "         '更新': 1,\n",
       "         '发布': 1,\n",
       "         '含': 1,\n",
       "         '开发': 1,\n",
       "         '版': 1,\n",
       "         '体验版': 1,\n",
       "         '内测': 1,\n",
       "         '稳定版': 1,\n",
       "         '暂不受': 1,\n",
       "         '影响': 1})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt(token[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cnt = cnt(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的', 703561),\n",
       " ('n', 381915),\n",
       " ('在', 263549),\n",
       " ('月', 189309),\n",
       " ('日', 166285),\n",
       " ('新华社', 142450),\n",
       " ('和', 134027),\n",
       " ('年', 123095),\n",
       " ('了', 121903),\n",
       " ('是', 100889),\n",
       " ('\\n', 89611),\n",
       " ('１', 88174),\n",
       " ('０', 84928),\n",
       " ('外代', 83268),\n",
       " ('中', 73920),\n",
       " ('中国', 71133),\n",
       " ('２', 70504),\n",
       " ('2017', 69894),\n",
       " ('记者', 62134),\n",
       " ('二线', 61998),\n",
       " ('将', 61395),\n",
       " ('与', 58295),\n",
       " ('等', 58141),\n",
       " ('为', 57004),\n",
       " ('5', 54578),\n",
       " ('照片', 52271),\n",
       " ('4', 51626),\n",
       " ('对', 50300),\n",
       " ('上', 47450),\n",
       " ('也', 47391),\n",
       " ('有', 45747),\n",
       " ('５', 40848),\n",
       " ('说', 39003),\n",
       " ('发展', 37619),\n",
       " ('他', 37186),\n",
       " ('３', 36902),\n",
       " ('以', 36863),\n",
       " ('国际', 35809),\n",
       " ('nn', 35327),\n",
       " ('４', 34648),\n",
       " ('比赛', 32221),\n",
       " ('６', 30566),\n",
       " ('到', 30089),\n",
       " ('人', 29561),\n",
       " ('从', 29480),\n",
       " ('6', 29002),\n",
       " ('都', 28013),\n",
       " ('不', 27958),\n",
       " ('后', 27383),\n",
       " ('当日', 27186)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_cnt.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6970"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_cnt['你']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4 1-gram与2-gram概率计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 单个word出现概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob1(word=''):\n",
    "    if word not in word_cnt: \n",
    "        #print(word,'is not in Token!')\n",
    "        return 1/len(token)\n",
    "    return word_cnt[word]/len(token)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002405354273228163"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob1('此外')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_2gram(token = []):\n",
    "    return [token[i]+token[i+1] for i in range(len(token)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_2 = token_2gram(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['此外自',\n",
       " '自本周',\n",
       " '本周6',\n",
       " '6月',\n",
       " '月12',\n",
       " '12日起',\n",
       " '日起除',\n",
       " '除小米',\n",
       " '小米手机',\n",
       " '手机6',\n",
       " '6等',\n",
       " '等15',\n",
       " '15款',\n",
       " '款机型',\n",
       " '机型外',\n",
       " '外其余',\n",
       " '其余机型',\n",
       " '机型已',\n",
       " '已暂停',\n",
       " '暂停更新']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_2[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['今天天气真不错']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_2gram(cut('今天天气真不错'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['今天天气', '真不错']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut('今天天气真不错')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_2_cnt = cnt(token_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P(Wn|Wn-1) = P(WnWn-1)/P(Wn-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob2(word1,word2):     #计算P(W2|W1) = P(W1W2)/P(W1)\n",
    "    if word1+word2 in token_2:\n",
    "        return word_2_cnt[word1+word2]/len(token_2)/prob1(word1)\n",
    "        #return word_2_cnt[word1+word2]/len(token_2)            #此处难道不是计算P(W1W2)?\n",
    "    else :\n",
    "        return 1/len(token_2)/prob1(word1)\n",
    "        #return 1/len(token_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000235849069983504"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob2('此外','你')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.5 计算句子的概率(默认2-gram模型)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_sentence(str,scheme = '2gram'):\n",
    "    if scheme == '2gram':\n",
    "        str_token = cut(str)\n",
    "        #str_token_2 = token_2gram(str_token)\n",
    "        prob = 1\n",
    "        for i,word in enumerate(str_token[:-1]):\n",
    "            #if i < len(str_token)-1:\n",
    "            #    word_ = str_token[i+1]\n",
    "            #    prob*=prob2(word,word_)\n",
    "            #else :\n",
    "            #    prob*=prob1(word)\n",
    "            if i == 0 :\n",
    "                prob*=prob1(word)\n",
    "            else :\n",
    "                word_ = str_token[i+1]\n",
    "                prob*=prob2(word,word_)\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.6 一些例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.947840448232294e-17"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_sentence('今天的天气真是不错啊')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.647645102528815e-17"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_sentence('小明今天抽奖抽到一台苹果手机')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.253941225157128e-16"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_sentence('小明今天抽奖抽到一架波音747')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.704733737087126e-11"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_sentence('洋葱奶昔来一杯')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.673005683217094e-08"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_sentence('养乐多绿来一杯')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: 一个桌子听着一个好看的女人 with Prb: 7.01023944263084e-18\n",
      "sentence: 这个篮球听着这个蓝色的篮球 with Prb: 1.184629888933195e-20\n",
      "sentence: 一个好看的小猫听着一个好看的小猫 with Prb: 6.971265649564411e-23\n",
      "sentence: 这个好看的篮球看着一个好看的小小的好看的篮球 with Prb: 3.687484316647029e-33\n",
      "sentence: 一个篮球看见这个小小的桌子 with Prb: 2.30083761608042e-14\n",
      "sentence: 这个好看的蓝色的小小的小猫看着这个女人 with Prb: 1.1667165302155732e-24\n",
      "sentence: 这个蓝色的桌子听着这个桌子 with Prb: 1.408020661719889e-19\n",
      "sentence: 一个篮球听着一个好看的小小的小猫 with Prb: 1.548338520226981e-23\n",
      "sentence: 一个好看的小小的篮球坐在这个小小的篮球 with Prb: 3.911435400877753e-24\n",
      "sentence: 这个好看的蓝色的女人看见这个好看的女人 with Prb: 9.131762156458161e-27\n"
     ]
    }
   ],
   "source": [
    "for sen in [generator(gram_struct, target='sentence') for i in range(10)]:\n",
    "    print('sentence: {} with Prb: {}'.format(sen, prob_sentence(sen)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 比较生成句子合理性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今天晚上请你吃大餐，我们一起吃日料 is more possible\n",
      "---- 今天晚上请你吃大餐，我们一起吃日料 with probility 3.329492941564565e-25\n",
      "---- 明天晚上请你吃大餐，我们一起吃苹果 with probility 1.9703012027613093e-25\n",
      "真是一只好看的小猫 is more possible\n",
      "---- 真事一只好看的小猫 with probility 1.024625101885699e-16\n",
      "---- 真是一只好看的小猫 with probility 9.645211952811829e-14\n",
      "今晚我去吃火锅 is more possible\n",
      "---- 今晚我去吃火锅 with probility 3.1847197581434764e-12\n",
      "---- 今晚火锅去吃我 with probility 1.0297580191975697e-13\n",
      "养乐多绿来一杯 is more possible\n",
      "---- 洋葱奶昔来一杯 with probility 7.704733737087126e-11\n",
      "---- 养乐多绿来一杯 with probility 5.673005683217094e-08\n"
     ]
    }
   ],
   "source": [
    "\n",
    "need_compared = [\n",
    "    \"今天晚上请你吃大餐，我们一起吃日料 明天晚上请你吃大餐，我们一起吃苹果\",\n",
    "    \"真事一只好看的小猫 真是一只好看的小猫\",\n",
    "    \"今晚我去吃火锅 今晚火锅去吃我\",\n",
    "    \"洋葱奶昔来一杯 养乐多绿来一杯\"\n",
    "]\n",
    "\n",
    "for s in need_compared:\n",
    "    s1, s2 = s.split()\n",
    "    p1, p2 = prob_sentence(s1), prob_sentence(s2)\n",
    "    \n",
    "    better = s1 if p1 > p2 else s2\n",
    "    \n",
    "    print('{} is more possible'.format(better))\n",
    "    print('-'*4 + ' {} with probility {}'.format(s1, p1))\n",
    "    print('-'*4 + ' {} with probility {}'.format(s2, p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
